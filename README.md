# CycleGAN: Horse-to-Zebra & Zebra-to-Horse Image Translation

This repository contains the implementation of CycleGAN for bidirectional image translation between the horse and zebra domains. CycleGAN is a generative adversarial network (GAN) model that enables image-to-image translation without paired examples during training. With this model, you can convert horse images to zebra images and vice versa, allowing for seamless transformation between the two domains.

# Dataset
The dataset used for this implementation consists of paired horse and zebra images. Unfortunately, we cannot provide the dataset directly within this repository due to size and licensing constraints. However, you can acquire the dataset from public sources or repositories and organize it accordingly. Or download the dataset from Kaggle repository <a href='https://www.kaggle.com/datasets/balraj98/horse2zebra-dataset'>Horse2zebra Dataset</a> 

# Losses
In CycleGAN, three distinct loss functions are utilized: adversarial loss, cycle consistency loss, and optional identity loss. 

<ul>
<li>The adversarial loss aims to train the generator to produce realistic images by distinguishing them from the real images using Mean Squared Error (MSE) loss.</li>
<li>
For the cycle consistency loss, the Wasserstein loss is employed instead of the traditional L1 norm loss. It ensures that translating an image from one domain to another and then back again generates a reconstructed image that closely resembles the original. </li>
<li>
Lastly, the identity loss, although optional, aims to preserve the identity of an input image from the target domain. Notably, the original paper did not utilize identity loss, leaving it as an optional component.</li>
</ul>

# Results
Here are some samples of the translated images generated by the trained CycleGAN model:

<ul>

## <li>Zebra-to-Horse</li>
<img src="https://github.com/Sameer-Ahmed7/CycleGAN/blob/main/Results/Zebra-to-Horse.jpg" alt="Zebra-to-Horse">


## <li>Horse-to-Zebra</li>
<img src="https://github.com/Sameer-Ahmed7/CycleGAN/blob/main/Results/Horse-to-Zebra.jpg" alt="Horse-to-Zebra">
</ul>

# Training Limitations
Due to limitations in the training environment (e.g., computational resources, time constraints, or limitations in the Google Colab platform), the model was trained for a reduced number of epochs, stopping at 128 epochs instead of the originally intended 200 epochs. That's the main reason, the model is not quite good. 

# Acknowledgments
This implementation is based on the original CycleGAN paper:

Zhu, J., Park, T., Isola, P., & Efros, A. A. (2017). Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. In Proceedings of the IEEE International Conference on Computer Vision (ICCV).





